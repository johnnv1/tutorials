{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/kornia/tutorials/blob/master/source/data_augmentation_sequential.ipynb)\n",
    "\n",
    "# Augmentation Sequential\n",
    "\n",
    "In this tutorial we will show how we can quickly perform **data augmentation for various tasks** (segmentation, detection, regression) using the features provided by the `kornia.augmentation.AugmentationSequential` API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and get data\n",
    "\n",
    "We install Kornia and some dependencies, and download a simple data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://tinypng.com/images/social/website.jpg -O panda.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from kornia import augmentation as K\n",
    "from kornia.augmentation import AugmentationSequential\n",
    "from kornia.geometry import bbox_to_mask\n",
    "from kornia.utils import image_to_tensor, tensor_to_image\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "to_pil = transforms.ToPILImage()\n",
    "\n",
    "\n",
    "def plot_resulting_image(img, bbox, keypoints, mask):\n",
    "    img = img * mask\n",
    "    img_draw = cv2.polylines(np.array(to_pil(img)), bbox.numpy(), isClosed=True, color=(255, 0, 0))\n",
    "    for k in keypoints[0]:\n",
    "        img_draw = cv2.circle(img_draw, tuple(k.numpy()[:2]), radius=6, color=(255, 0, 0), thickness=-1)\n",
    "    return img_draw\n",
    "\n",
    "\n",
    "img = cv2.imread(\"panda.jpg\", cv2.IMREAD_COLOR)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "img_tensor = image_to_tensor(img).float() / 255.0\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Augmentation Sequential and Different Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_list = AugmentationSequential(\n",
    "    K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=1.0),\n",
    "    K.RandomAffine(360, [0.1, 0.1], [0.7, 1.2], [30.0, 50.0], p=1.0),\n",
    "    K.RandomPerspective(0.5, p=1.0),\n",
    "    data_keys=[\"input\", \"bbox\", \"keypoints\", \"mask\"],\n",
    "    same_on_batch=False,\n",
    ")\n",
    "\n",
    "bbox = torch.tensor([[[[355, 10], [660, 10], [660, 250], [355, 250]]]])\n",
    "keypoints = torch.tensor([[[465, 115], [545, 116]]])\n",
    "mask = bbox_to_mask(torch.tensor([[[155, 0], [900, 0], [900, 400], [155, 400]]]), w, h)[None].float()\n",
    "\n",
    "img_out = plot_resulting_image(img_tensor, bbox[0], keypoints, mask[0])\n",
    "\n",
    "plt.imshow(img_out)\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tensor = aug_list(img_tensor, bbox.float(), keypoints.float(), mask)\n",
    "img_out = plot_resulting_image(\n",
    "    out_tensor[0][0],\n",
    "    out_tensor[1].int(),\n",
    "    out_tensor[2].int(),\n",
    "    out_tensor[3][0],\n",
    ")\n",
    "plt.imshow(img_out)\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tensor_inv = aug_list.inverse(*out_tensor)\n",
    "img_out = plot_resulting_image(\n",
    "    out_tensor_inv[0][0],\n",
    "    out_tensor_inv[1].int(),\n",
    "    out_tensor_inv[2].int(),\n",
    "    out_tensor_inv[3][0],\n",
    ")\n",
    "plt.imshow(img_out)\n",
    "plt.axis(\"off\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
