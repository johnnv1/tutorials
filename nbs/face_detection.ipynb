{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/kornia/tutorials/blob/master/source/face_detection.ipynb)\n",
    "\n",
    "# Face Detection and blurring\n",
    "\n",
    "In this tutorials we will show how to use\n",
    "- The [Face Detection](https://kornia.readthedocs.io/en/latest/applications/face_detection.html) API in CPU/GPU.\n",
    "- Blur the detected images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/kornia/kornia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import kornia as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from kornia.contrib import FaceDetector, FaceDetectorResult\n",
    "\n",
    "# select the device and type\n",
    "device = torch.device(\"cpu\")  # use 'cuda:0'\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the image and convert to a `torch.Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def get_data_directory(base):\n",
    "    path = os.path.join(\"../\", base)\n",
    "    if os.path.isdir(os.path.join(path, \"data\")):\n",
    "        return os.path.join(path, \"data/\")\n",
    "    return get_data_directory(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image and scale (if needed)\n",
    "img_raw = cv2.imread(get_data_directory(\"\") + \"crowd.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "# preprocess\n",
    "img = K.image_to_tensor(img_raw, keepdim=False).to(device, dtype)\n",
    "img = K.color.bgr_to_rgb(img)\n",
    "\n",
    "img_vis = K.tensor_to_image(img.byte().clone())  # to later visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(K.tensor_to_image(img.byte()))\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the [FaceDetector](https://kornia.readthedocs.io/en/latest/contrib.html#kornia.contrib.FaceDetector) object and apply to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the detector and find the faces !\n",
    "face_detection = FaceDetector().to(device, dtype)\n",
    "\n",
    "with torch.no_grad():\n",
    "    dets = face_detection(img)\n",
    "\n",
    "# to decode later the detections\n",
    "dets = [FaceDetectorResult(o) for o in dets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to crop the faces from the original image and apply blurring using the [gaussian_blurd2d](https://kornia.readthedocs.io/en/latest/filters.html?highlight=gaussian%20blur#kornia.filters.gaussian_blur2d) operator.\n",
    "\n",
    "Alternatively, explore other blur operator in [`kornia.filters`](https://kornia.readthedocs.io/en/latest/filters.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blurring paramters\n",
    "k: int = 21  # kernel_size\n",
    "s: float = 35.0  # sigma\n",
    "\n",
    "\n",
    "def apply_blur_face(img: torch.Tensor, img_vis: np.ndarray, x1, y1, x2, y2):\n",
    "    # crop the face\n",
    "    roi = img[..., y1:y2, x1:x2]\n",
    "\n",
    "    # apply blurring and put back to the visualisation image\n",
    "    roi = K.filters.gaussian_blur2d(roi, (k, k), (s, s))\n",
    "    roi = K.color.rgb_to_bgr(roi)\n",
    "    img_vis[y1:y2, x1:x2] = K.tensor_to_image(roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let draw the detections and save/visualize the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in dets:\n",
    "    # draw face bounding box around each detected face\n",
    "    top_left = b.top_left.int().tolist()\n",
    "    bottom_right = b.bottom_right.int().tolist()\n",
    "    scores = b.score.tolist()\n",
    "\n",
    "    for score, tp, br in zip(scores, top_left, bottom_right):\n",
    "        x1, y1 = tp\n",
    "        x2, y2 = br\n",
    "\n",
    "        if score < 0.7:\n",
    "            continue  # skip detection with low score\n",
    "        img_vis = cv2.rectangle(img_vis, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # blur the detected faces\n",
    "        apply_blur_face(img, img_vis, x1, y1, x2, y2)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(img_vis)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# save and show image\n",
    "cv2.imwrite(\"img_out.jpg\", img_vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with the Real Time Demo\n",
    "\n",
    "You can achieve 60 FPS in CPU using a standard WebCam.\n",
    "\n",
    "See: [https://github.com/kornia/kornia/blob/master/examples/face_detection/main_video.py](https://github.com/kornia/kornia/blob/master/examples/face_detection/main_video.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo(\"hzQroGp5FSQ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
