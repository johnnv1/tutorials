{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Image Classification: From Training to Inference within PyTorch ecosystem (timm)\"\n",
    "description: \"In this tutorial we are going to learn how to train a image classification model, and use it for inference. We are going to explore timm models, within Kornia Augmentation for a dataset from Hugging Face Hub.\"\n",
    "author:\n",
    "    - \"Jo√£o G. A. Amorim\"\n",
    "date: 02-10-2024\n",
    "categories:\n",
    "    - Basic\n",
    "    - Training\n",
    "    - Inference\n",
    "    - kornia.augmentation\n",
    "image: \"../tutorials/assets/image_classification.png\"\n",
    "---\n",
    "\n",
    "<a href=\"https://colab.sandbox.google.com/github/kornia/tutorials/blob/master/nbs/image_classification.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in google colab\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install kornia\n",
    "!pip install kornia-rs\n",
    "!pip install timm\n",
    "!pip install datasets[vision]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import random\n",
    "\n",
    "import kornia\n",
    "import numpy as np\n",
    "import timm\n",
    "from datasets import Image, load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring timm models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [PyTorch Image Models (timm)](https://github.com/huggingface/pytorch-image-models) is a collection of image models, layers, utilities, optimizers, schedulers, data-loaders / augmentations, and reference training / validation scripts that aim to pull together a wide variety of SOTA models with ability to reproduce ImageNet training results.\n",
    "\n",
    "Let's list all model available within pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names_pretrained = timm.list_models(pretrained=True)\n",
    "model_names = timm.list_models()\n",
    "\n",
    "k = 15\n",
    "\n",
    "print(\n",
    "    f\"Timm have a total of {len(model_names_pretrained)} pretrained models (with a total of {len(model_names)}), here is some of them:\"\n",
    ")\n",
    "for m in random.choices(model_names_pretrained, k=k):\n",
    "    print(f\"\\t-> `{m}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset and create the dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For datasets, we will use [Hugging Faces datasets library](https://github.com/huggingface/datasets), which you can explore the image classification in [ü§ó Hub](https://huggingface.co/datasets?task_categories=task_categories:image-classification&sort=trending).\n",
    "\n",
    "For these example, let's use the [beans dataset](https://huggingface.co/datasets/beans).\n",
    "\n",
    "> Beans leaf dataset with images of diseased and health leaves. Based on a leaf image, the goal of this task is to predict the disease type (Angular Leaf Spot and Bean Rust), if any.\n",
    "\n",
    "\n",
    "> Within ü§ó `datasets` library, your data can be stored in various places; they can be on your local machine‚Äôs disk, in a Github repository, and in in-memory data structures like Python dictionaries and Pandas DataFrames.\n",
    "\n",
    "Let's load the beans from ü§ó Hub using the ü§ó `datasets` library. For it we will use `load_dataset`, where we can specify what dataset part we want to load (usually `train`, `valid` and `test` are available), defined via the `split` parameter. We will also use `streaming=True`, which allow we work with a dataset without downloading all data. The data is downloaded as you iterate over the dataset. By setting the `cache_dir` parameter, you can manage where the `datasets` library will read/write the data in your disk, let's use the temporary directory. Check more about this function in the official docs: https://huggingface.co/docs/datasets/package_reference/loading_methods#datasets.load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"/tmp/hf/datasets/\"\n",
    "dataset = load_dataset(\"beans\", split=\"train\", streaming=True, cache_dir=data_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrieve the information of the dataset from the Hub. And also check it's features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(dataset.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(dataset.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, for image datasets, the library will automated decode (read) the images files using [Pillow](https://pypi.org/project/pillow/). If desired you can disable this decode.\n",
    "\n",
    "Within the `decode` option disable, instead of returning a PIL Image object, our dataset will return the path for the image and it's bytes (as a dictionary within `path` and `bytes`).\n",
    "\n",
    "At the moment (kornia v0.7.1), the `io` module, powered by [kornia-rs](https://github.com/kornia/kornia-rs) do not support reading data from bytes strings. So we are still using the default decode option, but you can check bellow how to disable it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"image\", Image(decode=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(dataset.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"image\", Image(decode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let's check it in two examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "n = 2\n",
    "device = \"cpu\"\n",
    "\n",
    "for sample in dataset:\n",
    "    print(f\"dataset item {counter}.\")\n",
    "    print(f'-> `image`: {sample[\"image\"]}')\n",
    "    print(f'-> `labels`: {sample[\"labels\"]}')\n",
    "\n",
    "    image = kornia.image_to_tensor(np.asarray(sample[\"image\"]))\n",
    "    print(f\"-> Image: Shape={image.shape} | Mean={image.mean(dim=(2, 3))} | Std={image.std(dim=(2, 3))}\")\n",
    "    if counter >= n:\n",
    "        break\n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
