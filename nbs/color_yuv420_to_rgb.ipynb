{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/kornia/tutorials/blob/master/source/color_yuv420_to_rgb.ipynb)\n",
    "\n",
    "# Convert RGB to YUV420"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data and libraries to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install kornia\n",
    "!pip install py7zr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget http://trace.eas.asu.edu/yuv/foreman/foreman_qcif.7z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import needed libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kornia\n",
    "import numpy as np\n",
    "\n",
    "# prepare the data, decompress so we have a foreman_qcif.yuv ready\n",
    "import py7zr\n",
    "import torch\n",
    "\n",
    "with py7zr.SevenZipFile(\"foreman_qcif.7z\", mode=\"r\") as z:\n",
    "    z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for reading the yuv file to torch tensor for use in Kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def read_frame(fname, framenum):\n",
    "    # A typical 420 yuv file is 3 planes Y, u then v with u/v a quartyer the size of Y\n",
    "    # Build rgb png images from foreman that is 3 plane yuv420\n",
    "    yuvnp = np.fromfile(fname, dtype=np.uint8, count=int(176 * 144 * 1.5), offset=int(176 * 144 * 1.5) * framenum)\n",
    "    y = torch.from_numpy(yuvnp[0 : 176 * 144].reshape((1, 1, 144, 176)).astype(np.float32) / 255.0)\n",
    "\n",
    "    uv_tmp = yuvnp[176 * 144 : int(144 * 176 * 3 / 2)].reshape((1, 2, int(144 / 2), int(176 / 2)))\n",
    "    # uv (chroma) is typically defined from -0.5 to 0.5 (or -128 to 128 for 8-bit)\n",
    "    uv = torch.from_numpy(uv_tmp.astype(np.float32) / 255.0) - 0.5\n",
    "    return (y, uv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample what the images look like Y, u, v channels separaatly and then converted to rgn through kornia (and back to numpy in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y, uv) = read_frame(\"foreman_qcif.yuv\", 0)  # using compression classic foreman\n",
    "plt.imshow((y.numpy()[0, 0, :, :] * 255.0).astype(np.uint8), cmap=\"gray\")\n",
    "plt.figure()\n",
    "plt.imshow(((uv.numpy()[0, 0, :, :] + 0.5) * 255.0).astype(np.uint8), cmap=\"gray\")\n",
    "plt.figure()\n",
    "plt.imshow(((uv.numpy()[0, 1, :, :] + 0.5) * 255.0).astype(np.uint8), cmap=\"gray\")\n",
    "\n",
    "rgb = np.moveaxis(kornia.color.yuv420_to_rgb(y, uv).numpy(), 1, 3).reshape((144, 176, 3))\n",
    "\n",
    "print(\"as converted through kornia\")\n",
    "plt.figure()\n",
    "plt.imshow((rgb * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can use these in some internal Kornia algorithm implementations. Lets pretend we want to do LoFTR on the red channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "loftr = kornia.feature.LoFTR(\"outdoor\")\n",
    "(y0, uv0) = read_frame(\"foreman_qcif.yuv\", 175)\n",
    "(y1, uv1) = read_frame(\"foreman_qcif.yuv\", 185)\n",
    "rgb0 = kornia.color.yuv420_to_rgb(y0, uv0)\n",
    "rgb1 = kornia.color.yuv420_to_rgb(y1, uv1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    matches = loftr({\"image0\": rgb0[:, 0:1, :, :], \"image1\": rgb1[:, 0:1, :, :]})\n",
    "\n",
    "matched_image = cv2.drawMatches(\n",
    "    np.moveaxis(rgb0.numpy()[0, :, :, :] * 255.0, 0, 2).astype(np.uint8),\n",
    "    [cv2.KeyPoint(x[0], x[1], 0) for x in matches[\"keypoints0\"].numpy()],\n",
    "    np.moveaxis(rgb1.numpy()[0, :, :, :] * 255.0, 0, 2).astype(np.uint8),\n",
    "    [cv2.KeyPoint(x[0], x[1], 0) for x in matches[\"keypoints1\"].numpy()],\n",
    "    [cv2.DMatch(x, x, 0) for x in range(len(matches[\"keypoints1\"].numpy()))],\n",
    "    None,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(30, 30))\n",
    "plt.imshow(matched_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
