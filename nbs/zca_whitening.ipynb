{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kornia/tutorials/blob/master/source/zca_whitening.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZCA Whitening\n",
    "\n",
    "The following tutorial will show you how to perform ZCA data whitening on a dataset using ```kornia.enhance.zca```. The documentation for ZCA whitening can be found [here](https://kornia.readthedocs.io/en/latest/enhance.html#kornia.enhance.ZCAWhitening).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install kornia numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import kornia as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select runtime device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZCA on MNIST\n",
    "\n",
    "Download and load the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "dataset = datasets.MNIST(\"./data/mnist\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack whole dataset in order to fit ZCA on whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in range(len(dataset)):\n",
    "    im, _ = dataset[i]\n",
    "    images.append(im)\n",
    "images = torch.stack(images, dim=0).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an ZCA object and fit the transformation in the forward pass. Setting ```include_fit``` is necessary if you need to include the ZCA fitting processing the backwards pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zca = K.enhance.ZCAWhitening(eps=0.1)\n",
    "images_zca = zca(images, include_fit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result shown should enhance the edges of the MNIST digits because the regularization parameter $\\epsilon$ increases the importance of the higher frequencies which typically correspond to the lowest eigenvalues in ZCA. The result looks similar to the demo from the [Stanford ZCA tutorial](http://ufldl.stanford.edu/tutorial/unsupervised/ExercisePCAWhitening/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_im = make_grid(images[0:30], nrow=5, normalize=True).cpu().numpy()\n",
    "grid_zca = make_grid(images_zca[0:30], nrow=5, normalize=True).cpu().numpy()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(np.transpose(grid_im, [1, 2, 0]))\n",
    "plt.title(\"Input Images\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(np.transpose(grid_zca, [1, 2, 0]))\n",
    "plt.title(r\"ZCA Images $\\epsilon = 0.1$\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZCA on CIFAR-10\n",
    "\n",
    "\n",
    "In the next example, we explore using ZCA on the CIFAR 10 dataset, which is a dataset of color images (e.g 4-D tensor $[B, C, H, W]$). In the cell below, we prepare the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "dataset = datasets.CIFAR10(\"./data/cifar\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "images = []\n",
    "for i in range(len(dataset)):\n",
    "    im, _ = dataset[i]\n",
    "    images.append(im)\n",
    "images = torch.stack(images, dim=0).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show another way to fit the ZCA transform using the ```fit``` method useful when ZCA is included in [data augumentation pipelines](https://kornia.readthedocs.io/en/latest/tutorials/data_augmentation.html). Also if ```compute_inv = True```, this enables the computation of inverse ZCA transform in case a reconstruction is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zca = K.enhance.ZCAWhitening(eps=0.1, compute_inv=True)\n",
    "zca.fit(images)\n",
    "zca_images = zca(images)\n",
    "image_re = zca.inverse_transform(zca_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the higher frequency details are more present in the ZCA normalized images for CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_im = make_grid(images[0:30], nrow=5, normalize=True).cpu().numpy()\n",
    "grid_zca = make_grid(zca_images[0:30], nrow=5, normalize=True).cpu().numpy()\n",
    "grid_re = make_grid(image_re[0:30], nrow=5, normalize=True).cpu().numpy()\n",
    "\n",
    "\n",
    "err_grid = grid_re - grid_im  # Compute error image\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(np.transpose(grid_im, [1, 2, 0]))\n",
    "plt.title(\"Input Images\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(np.transpose(grid_zca, [1, 2, 0]))\n",
    "plt.title(r\"ZCA Images $\\epsilon = 0.1$\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(np.transpose(grid_re, [1, 2, 0]))\n",
    "plt.title(r\"Reconstructed Images\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(np.sum(abs(np.transpose(err_grid, [1, 2, 0])), axis=-1))\n",
    "plt.colorbar()\n",
    "plt.title(\"Error Image\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiability of ZCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will as simple Gaussian dataset with a mean (3,3) and a diagonal covariance of 1 and 9 to explore the differentiability of ZCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 100  # Number of points in the dataset\n",
    "torch.manual_seed(1234)\n",
    "x = torch.cat([torch.randn((num_data, 1), requires_grad=True), 3 * torch.randn((num_data, 1), requires_grad=True)], dim=1) + 3\n",
    "\n",
    "plt.scatter(x.detach().numpy()[:, 0], x.detach().numpy()[:, 1])\n",
    "plt.xlim([-10, 10])\n",
    "plt.ylim([-10, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we explore the affect of the `detach_transform` option when computing the backwards pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zca_detach = K.enhance.ZCAWhitening(eps=1e-6, detach_transforms=True)\n",
    "zca_grad = K.enhance.ZCAWhitening(eps=1e-6, detach_transforms=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, the Jacobian between the input and output of the ZCA transform should be same for all data points in the detached case since the transform acts as linear transform (e.g $T(X-\\mu)$). In the non-detached case, the Jacobian should vary across datapoints since the input affects the computation of the ZCA transformation matrix (e.g. $T(X)(X-\\mu(X))$). As the number of samples increases, the Jacobians in the detached and non-detached cases should be roughly the same since the influence of a single datapoint decreases. You can test this by changing ```num_data``` . Also note that ```include_fit=True``` is included in the forward pass since creation of the transform matrix needs to be included in the forward pass in order to correctly compute the backwards pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd as autograd\n",
    "\n",
    "J = autograd.functional.jacobian(lambda x: zca_detach(x, include_fit=True), x)\n",
    "\n",
    "num_disp = 5\n",
    "print(f\"Jacobian matrices detached for the first {num_disp} points\")\n",
    "for i in range(num_disp):\n",
    "    print(J[i, :, i, :])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "J = autograd.functional.jacobian(lambda x: zca_grad(x, include_fit=True), x)\n",
    "print(f\"Jacobian matrices attached for the first {num_disp} points\")\n",
    "for i in range(num_disp):\n",
    "    print(J[i, :, i, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we plot the ZCA whitened data. Note that setting the `include_fit` to `True` stores the resulting transformations for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_zca = zca_detach(x).detach().numpy()\n",
    "plt.scatter(x_zca[:, 0], x_zca[:, 1])\n",
    "plt.ylim([-4, 4])\n",
    "plt.xlim([-4, 4])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
