{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/kornia/tutorials/blob/master/source/data_augmentation_segmentation.ipynb)\n",
    "\n",
    "# Data Augmentation Semantic Segmentation\n",
    "\n",
    "In this tutorial we will show how we can quickly perform **data augmentation for semantic segmenation** using the `kornia.augmentation` API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and get data\n",
    "\n",
    "We install Kornia and some dependencies, and download a simple data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install kornia opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget http://www.zemris.fer.hr/~ssegvic/multiclod/images/causevic16semseg3.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import kornia as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Augmentation pipeline\n",
    "\n",
    "We define a class to define our augmentation API using an `nn.Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAugmentation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # we define and cache our operators as class members\n",
    "        self.k1 = K.augmentation.ColorJitter(0.15, 0.25, 0.25, 0.25)\n",
    "        self.k2 = K.augmentation.RandomAffine([-45.0, 45.0], [0.0, 0.15], [0.5, 1.5], [0.0, 0.15])\n",
    "\n",
    "    def forward(self, img: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
    "        # 1. apply color only in image\n",
    "        # 2. apply geometric tranform\n",
    "        img_out = self.k2(self.k1(img))\n",
    "\n",
    "        # 3. infer geometry params to mask\n",
    "        # TODO: this will change in future so that no need to infer params\n",
    "        mask_out = self.k2(mask, self.k2._params)\n",
    "\n",
    "        return img_out, mask_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and apply the transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path: str) -> torch.Tensor:\n",
    "    data: np.ndarray = cv2.imread(data_path, cv2.IMREAD_COLOR)\n",
    "    data_t: torch.Tensor = K.image_to_tensor(data, keepdim=False)\n",
    "    data_t = K.color.bgr_to_rgb(data_t)\n",
    "    data_t = K.enhance.normalize(data_t, torch.tensor(0.0), torch.tensor(255.0))\n",
    "    img, labels = data_t[..., :571], data_t[..., 572:]\n",
    "    return img, labels\n",
    "\n",
    "\n",
    "# load data (B, C, H, W)\n",
    "img, labels = load_data(\"causevic16semseg3.png\")\n",
    "\n",
    "# create augmentation instance\n",
    "aug = MyAugmentation()\n",
    "\n",
    "# apply the augmenation pipelone to our batch of data\n",
    "img_aug, labels_aug = aug(img, labels)\n",
    "\n",
    "# visualize\n",
    "img_out = torch.cat([img, labels], dim=-1)\n",
    "plt.imshow(K.tensor_to_image(img_out))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# generate several samples\n",
    "num_samples: int = 10\n",
    "\n",
    "for img_id in range(num_samples):\n",
    "    # generate data\n",
    "    img_aug, labels_aug = aug(img, labels)\n",
    "    img_out = torch.cat([img_aug, labels_aug], dim=-1)\n",
    "\n",
    "    # save data\n",
    "    plt.figure()\n",
    "    plt.imshow(K.tensor_to_image(img_out))\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"img_{img_id}.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
