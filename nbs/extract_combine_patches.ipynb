{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34fb3a3e",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/kornia/tutorials/blob/master/source/extract-combine-patches.ipynb)\n",
    "\n",
    "# Extracting and Combining Tensor Patches\n",
    "\n",
    "In this tutorial we will show how you can extract and combine tensor patches using kornia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c3683",
   "metadata": {},
   "source": [
    "## Install and get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611b350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "# Get sample data\n",
    "!wget https://tinypng.com/images/social/website.jpg -O panda.jpg\n",
    "# Install latest kornia\n",
    "!pip install git+https://github.com/kornia/kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033903e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from kornia.contrib import (\n",
    "    CombineTensorPatches,\n",
    "    ExtractTensorPatches,\n",
    "    combine_tensor_patches,\n",
    "    extract_tensor_patches,\n",
    ")\n",
    "from kornia.utils import image_to_tensor, tensor_to_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb4bd6d",
   "metadata": {},
   "source": [
    "## Using Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7419ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = 8, 8\n",
    "win = 4\n",
    "pad = 2\n",
    "\n",
    "image = torch.randn(2, 3, h, w)\n",
    "print(image.shape)\n",
    "tiler = ExtractTensorPatches(window_size=win, stride=win, padding=pad)\n",
    "merger = CombineTensorPatches(original_size=(h, w), window_size=win, unpadding=pad)\n",
    "image_tiles = tiler(image)\n",
    "print(image_tiles.shape)\n",
    "new_image = merger(image_tiles)\n",
    "print(new_image.shape)\n",
    "assert (image == new_image).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e9bd7e",
   "metadata": {},
   "source": [
    "## Using Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad0bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = 8, 8\n",
    "win = 4\n",
    "pad = 2\n",
    "\n",
    "image = torch.randn(1, 1, h, w)\n",
    "print(image.shape)\n",
    "patches = extract_tensor_patches(image, window_size=win, stride=win, padding=pad)\n",
    "print(patches.shape)\n",
    "restored_img = combine_tensor_patches(patches, original_size=(h, w), window_size=win, stride=win, unpadding=pad)\n",
    "print(restored_img.shape)\n",
    "assert (image == restored_img).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672fb037",
   "metadata": {},
   "source": [
    "While using these functions, it is important to keep track of the following points:\n",
    "\n",
    "1. Image after padding must be divisible by window_size \n",
    "2. CombineTensorPatches only works with stride == window_size (PRs are welcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d12d26",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d9cdb8",
   "metadata": {},
   "source": [
    "All parameters of extract and combine functions accept a **single int** or **tuple of two ints**. Padding (for extract) and unpadding (for combine) also accept a **tuple of four ints**. Since padding is an integral part of these functions, it's important to note the following:\n",
    "\n",
    "- If padding is `p` -> it means both height and width are padded by `2*p`\n",
    "- If padding is `(ph, pw)` -> it means height is padded by `2*ph` and width is padded by `2*pw` \n",
    "- If padding is `(p1, p2, p3, p4)` -> it means image is padded by `p1` at the top, by `p2` at the bottom, by `p3` on the left, and by `p4` on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f5026e",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01add821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_combine(image, window_size, padding):\n",
    "    h, w = image.shape[-2:]\n",
    "    tiler = ExtractTensorPatches(window_size=window_size, stride=window_size, padding=padding)\n",
    "    merger = CombineTensorPatches(original_size=(h, w), window_size=window_size, unpadding=padding)\n",
    "    image_tiles = tiler(image)\n",
    "    print(f\"Shape of tensor patches = {image_tiles.shape}\")\n",
    "    merged_image = merger(image_tiles)\n",
    "    print(f\"Shape of merged image = {merged_image.shape}\")\n",
    "    assert (image == merged_image).all()\n",
    "    return merged_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c9c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.randn(2, 3, 9, 9)\n",
    "_ = extract_and_combine(image, window_size=(4, 4), padding=(2, 1, 2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c2d65a",
   "metadata": {},
   "source": [
    "Why is padding = (2, 1, 2, 1)?\n",
    "\n",
    "Recall that we need to ensure the padded image is divisible by `window_size`. The image is of size `(9, 9)` and `window_size` = `(4, 4)`, so we need to pad it by 3 units. In the cell above we padded the top by 2, bottom by 1, left by 2 and right by 1 i.e. `padding = (2, 1, 2, 1)`. You could have also used `padding = (1, 2, 1, 2)` to achieve the same result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9529ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.randn(2, 3, 9, 9)\n",
    "_ = extract_and_combine(image, window_size=(4, 4), padding=(1, 2, 1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62976aa7",
   "metadata": {},
   "source": [
    "These functions also work with rectangular images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65659e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_image = torch.randn(1, 1, 8, 6)\n",
    "print(rect_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c95f3da",
   "metadata": {},
   "source": [
    "If we use the same `window_size = (4,4)`, we can see that the height (8) is already divisible by `window_size` but this is not the case for width (6). To fix this, we just need to pad the width dimension by 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a07b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_image = extract_and_combine(rect_image, window_size=(4, 4), padding=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bb44a8",
   "metadata": {},
   "source": [
    "Recall that when padding is a tuple of ints `(ph, pw)`, the height and width are padded by `2*ph` and `2*pw` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7997ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that the original image and restored image are the same\n",
    "assert (restored_image == rect_image).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f1fabf",
   "metadata": {},
   "source": [
    "Let's now visualize how extraction and combining works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bf7ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample image\n",
    "img = cv2.imread(\"panda.jpg\", cv2.IMREAD_COLOR)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6efc3d",
   "metadata": {},
   "source": [
    "For extraction we need image to be a tensor of shape `BCHW`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade0dba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert img array to img tensor\n",
    "img_tensor = image_to_tensor(img).float() / 255.0\n",
    "img_tensor = img_tensor.unsqueeze(0)\n",
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4b9377",
   "metadata": {},
   "source": [
    "We will use `window_size = (400, 400)` to extract 6 tiles of shape `(400, 400)` and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a0b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set window size\n",
    "win = 400\n",
    "# Calculate required padding\n",
    "h_pad = (win - (h % win)) // 2\n",
    "w_pad = (win - (w % win)) // 2\n",
    "pad = (h_pad, w_pad)\n",
    "\n",
    "tiler = ExtractTensorPatches(window_size=win, stride=win, padding=pad)\n",
    "image_tiles = tiler(img_tensor)\n",
    "print(f\"Shape of image tiles = {image_tiles.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eb1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "fig, axs = plt.subplots(2, 3, figsize=(8, 8))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in range(len(image_tiles[0])):\n",
    "    axs[i].axis(\"off\")\n",
    "    axs[i].imshow(tensor_to_image(image_tiles[0][i]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639cf033",
   "metadata": {},
   "source": [
    "Finally, let's combine the patches and visualize the resulting image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695014f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merger = CombineTensorPatches(original_size=(h, w), window_size=win, unpadding=pad)\n",
    "merged_image = merger(image_tiles)\n",
    "print(f\"Shape of restored image = {merged_image.shape}\")\n",
    "\n",
    "plt.imshow(tensor_to_image(merged_image[0]))\n",
    "plt.axis(\"off\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
