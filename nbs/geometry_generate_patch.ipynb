{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/kornia/tutorials/blob/master/source/geometry_generate_patch.ipynb)\n",
    "\n",
    "# Image patch generation\n",
    "\n",
    "In this tutorial we are going to learn how to generate image patches using `kornia.geometry` components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install kornia matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://github.com/kornia/data/raw/main/homography/img1.ppm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load libraries and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import kornia as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image: np.ndarray, height: int = 10, width: int = 10):\n",
    "    \"\"\"Utility function to plot images.\"\"\"\n",
    "    plt.figure(figsize=(height, width))\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread(data_path: str) -> torch.Tensor:\n",
    "    \"\"\"Utility function that load an image an convert to torch.\"\"\"\n",
    "    # open image using OpenCV (HxWxC)\n",
    "    img: np.ndarray = cv2.imread(data_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # cast image to torch tensor and convert to RGB\n",
    "    img_t: torch.Tensor = K.utils.image_to_tensor(img, keepdim=False)  # BxCxHxW\n",
    "    img_t = K.color.bgr_to_rgb(img_t)\n",
    "\n",
    "    return img_t.float() / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and show the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "timg: torch.Tensor = imread(\"img1.ppm\")\n",
    "\n",
    "imshow(K.tensor_to_image(timg), 10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section we are going to take the original image and generate random crops of a given size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_crop = K.augmentation.RandomCrop((64, 64))\n",
    "\n",
    "patch = torch.cat([random_crop(timg) for _ in range(15)], dim=-1)\n",
    "\n",
    "imshow(K.tensor_to_image(patch[0]), 22, 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will show how to crop patches and apply forth and back random geometric transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform a patch\n",
    "\n",
    "random_crop = K.augmentation.RandomCrop((64, 64))\n",
    "random_affine = K.augmentation.RandomAffine([-15, 15], [0.0, 0.25])\n",
    "\n",
    "# crop\n",
    "patch = random_crop(timg)\n",
    "\n",
    "# transform and retrieve transformation\n",
    "patch_affine = random_affine(patch)\n",
    "transformation = random_affine.get_transformation_matrix(patch)\n",
    "\n",
    "# invert patch\n",
    "_, _, H, W = patch.shape\n",
    "patch_inv = K.geometry.warp_perspective(patch_affine, torch.inverse(transformation), (H, W))\n",
    "\n",
    "# visualise - (original, transformed, reconstructed)\n",
    "patches_vis = torch.cat([patch, patch_affine, patch_inv], dim=-1)\n",
    "imshow(K.tensor_to_image(patches_vis), 15, 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
