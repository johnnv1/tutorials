{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/kornia/tutorials/blob/master/source/image_points_example.ipynb)\n",
    "\n",
    "# Image and Keypoints augmentations\n",
    "\n",
    "In this tutorial we leverage [`kornia.augmentation.AugmentationSequential`](https://kornia.readthedocs.io/en/latest/augmentation.container.html#kornia.augmentation.container.AugmentationSequential) to apply augmentations to image and transform reusing the applied geometric transformation to a set of associated keypoints.\n",
    "\n",
    "This is useful for detection networks or geometric problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install kornia kornia_rs matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://github.com/kornia/data/raw/main/arturito.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kornia as K\n",
    "import torch\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = K.io.load_image(\"arturito.jpg\", K.io.ImageLoadType.RGB32)\n",
    "img = img[None]  # 1xCxHxW / fp32 / [0, 1]\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw points and show image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = torch.tensor([[[125, 40.0], [185.0, 75.0]]])  # BxNx2 [x,y]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.add_patch(plt.Circle((coords[0, 0, 0], coords[0, 0, 1]), color=\"r\"))\n",
    "ax.add_patch(plt.Circle((coords[0, 1, 0], coords[0, 1, 1]), color=\"r\"))\n",
    "\n",
    "ax.imshow(K.tensor_to_image(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize points and show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_op = K.augmentation.AugmentationSequential(\n",
    "    K.augmentation.Resize((100, 200), antialias=True), data_keys=[\"input\", \"keypoints\"]\n",
    ")\n",
    "\n",
    "print(resize_op.transform_matrix)\n",
    "\n",
    "img_resize, coords_resize = resize_op(img, coords)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.add_patch(plt.Circle((coords_resize[0, 0, 0], coords_resize[0, 0, 1]), color=\"r\"))\n",
    "ax.add_patch(plt.Circle((coords_resize[0, 1, 0], coords_resize[0, 1, 1]), color=\"r\"))\n",
    "\n",
    "ax.imshow(K.tensor_to_image(img_resize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop image and points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_op = K.augmentation.AugmentationSequential(K.augmentation.CenterCrop((100, 200)), data_keys=[\"input\", \"keypoints\"])\n",
    "print(crop_op.transform_matrix)\n",
    "\n",
    "img_resize, coords_resize = crop_op(img, coords)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.add_patch(plt.Circle((coords_resize[0, 0, 0], coords_resize[0, 0, 1]), color=\"r\"))\n",
    "ax.add_patch(plt.Circle((coords_resize[0, 1, 0], coords_resize[0, 1, 1]), color=\"r\"))\n",
    "\n",
    "ax.imshow(K.tensor_to_image(img_resize))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
